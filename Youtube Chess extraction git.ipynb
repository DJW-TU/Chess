{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import csv\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "# API Key generated from the Youtube API console \n",
    "api_key = \"Please enter your youtube API Key\" #(https://developers.google.com/youtube/v3/getting-started)\n",
    "# Establishing connection with the YouTube API key\n",
    "youtube  = build('youtube','v3',developerKey=api_key)\n",
    "# Setting up the directory location e.g. \n",
    "os.chdir('C:/Users/dominik/Documents/GitHub/Chess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 of the code\n",
    "# This function helps us to fetch the Youtube channel playlist data\n",
    "def youtube_playlist_data(id):\n",
    "    token = None\n",
    "    # Using the API's list function to retrive the channel data\n",
    "    y_data = youtube.channels().list(id=id,part='contentDetails').execute()\n",
    "    # Retrieving the \"uploads\" playlist Id from the channel\n",
    "    youtube_playlist_id = y_data['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    video_data = []\n",
    "    # The while loop which continues until the items are present in the playlist\n",
    "    while 1:\n",
    "        y_playlist_data = youtube.playlistItems().list(playlistId = youtube_playlist_id, part = 'snippet', maxResults = 50, pageToken = token).execute()  #Retrieving the playlist items snippet with a max result of 50 in each iteration\n",
    "        video_data = video_data + y_playlist_data['items']\n",
    "        # Update the token so as to get the next data\n",
    "        token = y_playlist_data.get('nextPageToken')\n",
    "        # If there is no token break the loop\n",
    "        if token is None:\n",
    "            break\n",
    "    # Return the final collected data\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 of the code\n",
    "# Here we pass the channel id of which the data needs to be retrieved\n",
    "y_video_data = youtube_playlist_data('UCL5YbN5WLFD8dLIegT5QAbA')\n",
    "# Initializing the title variable\n",
    "title = []\n",
    "# Initializing the description variable\n",
    "description = []\n",
    "# Initializing the video_id\n",
    "video_id = []\n",
    "# Initializing the thumbnail_default variable\n",
    "thumbnail_default = []\n",
    "# Initializing the thumbnail_standard variable\n",
    "thumbnail_standard = []\n",
    "# iterating through videos data one by one\n",
    "for data in y_video_data:\n",
    "    # Retrieving and appending the video title\n",
    "     title.append(data['snippet']['title'])\n",
    "    # Retrieving and appending the description\n",
    "     description.append(data['snippet']['description'])\n",
    "    # Retrieving and appending the video_id\n",
    "     video_id.append(\"https://www.youtube.com/watch?v=\" + data['snippet']['resourceId']['videoId'])   \n",
    "    # Check whether the thumbnail attribute is present\n",
    "     if 'thumbnails' in data['snippet'].keys():\n",
    "        if 'default' in data['snippet']['thumbnails'].keys():\n",
    "            # If thumbnail default present append the data\n",
    "            thumbnail_default.append(data['snippet']['thumbnails']['default']['url'])\n",
    "        else:\n",
    "            # If thumbnail default not present append 'Null'\n",
    "            thumbnail_default.append('Null')\n",
    "        if 'standard' in data['snippet']['thumbnails'].keys():\n",
    "            # If thumbnail standard present append the data\n",
    "            thumbnail_standard.append(data['snippet']['thumbnails']['standard']['url'])\n",
    "        else:\n",
    "            # If thumbnail standard not present append 'Null'\n",
    "            thumbnail_standard.append('Null')\n",
    "     else:\n",
    "         thumbnail_default.append('Null')\n",
    "         thumbnail_standard.append('Null')\n",
    "final_data = {'video_title': title,'video_id':video_id, 'Description':description, 'thumbnail_default': thumbnail_default, 'thumbnail_standard':thumbnail_standard} # Merge the data to form the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chess openings\n",
    "openings = pd.read_csv('C:/Users/dominik/Documents/GitHub/Chess/chess_openings.csv')\n",
    "openings[\"moves\"].iloc[1]\n",
    "file = pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to cluster videos of channel\n",
    "def definator(df,column1,column2):\n",
    "    ids = list()\n",
    "    for i in range(len(openings[\"moves\"])):\n",
    "        moves = openings[\"moves\"].iloc[i]\n",
    "        #return all video urls with above opening\n",
    "        df[column1].str.contains(moves)\n",
    "        url_list = df.loc[df[column1].str.contains(moves)][column2].tolist()\n",
    "        # append video_urls to list & define if list contains videos or not\n",
    "        if len(url_list) > 0: \n",
    "            ids.append(url_list)\n",
    "        else:\n",
    "            ids.append(None)\n",
    "        url_list = list()\n",
    "        #increase i\n",
    "        i=i+1\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of videos & append list to dataframe\n",
    "videos = definator(file,\"Description\",\"video_id\")\n",
    "openings[\"videos\"] = videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear all openings, which are not used\n",
    "openings = openings.dropna()\n",
    "#split video list to columns\n",
    "openings2 = openings[\"videos\"].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge singular videos_urls & initial opening dataframe\n",
    "openings_final = pd.concat([openings,openings2], axis=1)\n",
    "#append counter of \n",
    "openings_final[\"count_videos\"] = openings_final.count(axis=1)\n",
    "#saving the file to csv format\n",
    "openings_final.to_csv('opening_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv('agadmator.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
